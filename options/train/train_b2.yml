mode: sr
gpu_ids: [0]
scale: 4  #todo:
is_train: true
rgb_range: 255
self_ensemble: false # only used for testing
use_chop: false
save_image: false

datasets:
    train: # train datasets
        mode: LRHR
        dataroot_HR: /media/ser606/Data/train_set_noAug/DIV2K_x4/DIV2K_mod_x4_npy
        dataroot_LR: /media/ser606/Data/train_set_noAug/DIV2K_x4/DIV2K_LR_x4_npy
        data_type: npy
        n_workers: 4
        batch_size: 16
        LR_size: 48
        use_flip: true
        use_rot: true
        noise: .

    val: # validation datasets
        mode: LRHR
        dataroot_HR: val_test_img/infrared20_mod_x4
        dataroot_LR: val_test_img/infrared20_LR_x4
        data_type: img

## hyper-parameters for network architecture
networks:
    which_model: EDenseUpDown # this value of must be same with the filename of 'your_network_name'.py
    growthRate: 16
    num_features: 64
    compress: 32
    in_channels: 3
    iterations: 2
    nDenselayer: 4
    nBlock: 4 # the block in each IRU is nblock/2

# the setting for optimizer, loss function, learning_strategy, etc.
solver:
    type: ADAM
    learning_rate: 0.0001
    weight_decay: 0
    lr_scheme: MultiStepLR
    lr_steps: [200, 200, 300, 400]
    lr_gamma: 0.5
    loss_type: myloss
    manual_seed: 0
    num_epochs: 200
    skip_threshold: 3
    split_batch: 2
    save_ckp_step: 50
    save_vis_step: 1
    pretrain: null
    pretrained_path: experiments/EDENSEUPDOWN_in3f64_x3/epochs/best_ckp.pth

